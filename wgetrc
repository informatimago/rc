convertlinks=on
#noparent=on
robots=off
spanhosts=off

# progress=bar
# dotstyle=mega
# dotstyle=binary

user_agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.9) Gecko/20020513"
# -U "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.9) Gecko/20020513"



# -A htm,html,jpg,jpeg,gif,png,txt,js,css This only gets files of the given extensions. This is
#   useful if the webpage links to zip files or other junk.
# –wait=1 It’s courteous to give a second of wait between each fetch since I’m downloading so many
#   files.
# –random-wait This is to foil servers that see nearly constant wait times.
# -e robots=off Since I’m not being malicious, I turn robots.txt obedience off. I’m caching the
#    site for offline use, so overall I’m reducing traffic to the site.
# –mirror A combination of other options used to mirror a site.
# –no-parent Often a page links back to the homepage, and I don’t want to fetch that.
# –page-requisites Get all script and css files associated with the page.
# –convert-links Convert the links of pages downloaded so they point to local versions.
# –html-extensions Add .html to files downloaded that didn’t have an extension.

# --A htm,html,jpg,jpeg,gif,png,txt,js,css
# --wait=1 --random-wait --e robots=off --mirror --no-parent --page-requisites --convert-links --html-extensions
